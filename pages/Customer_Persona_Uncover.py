from sklearn.tree import DecisionTreeClassifier, export_text

from shared.const import others_label, CALL
from shared.form import show_email_form
from shared.rfm import build_rfm
from shared.simulate import simulate_for_segmentation
import streamlit as st
import pandas as pd


# Translate rules to human-readable
def parse_rule_line(rule_line):
    rule_depth = rule_line.count('|   ')
    content = rule_line.strip().replace('|--- ', '').replace('|   ', '')

    if 'class:' in content:
        label = content.split(':')[-1].strip()
        return rule_depth, f"THEN â†’ {'VIP' if label == '1' else 'Not VIP'}"
    else:
        parts = content.split(' ')
        feature = parts[0].replace('_', ' ')
        op = parts[1]
        value = parts[2] if parts[2] != "" else parts[3]
        if op == '<=':
            condition = f"{feature} is **No**" if value == "0.50" else f"{feature} â‰¤ {value}"
        else:
            condition = f"{feature} is **Yes**" if value == "0.50" else f"{feature} > {value}"
        return rule_depth, f"IF {condition}"

# Parameters
num_users = 500
num_products = 100
num_transactions = 10000

simulated_df = simulate_for_segmentation(num_users, num_products, num_transactions)

st.title("Customer Persona Uncover")
st.write("#### Simulated data sample")
st.caption("For presentation purposes data is 100% simulated.")
# st.caption("Dataset is made of ~0.5M UK-based non-store online retail transactions. A few rows sample: ")
df_display = simulated_df.reset_index(drop=True)
df_display.index = [''] * len(df_display)
st.dataframe(df_display.head(3))

category_options = ["Select a category..."] + list(simulated_df['category'].unique())
st.write("#### From raw transactional data to Customer Personas")
st.write("Let's see what we can find!")
category = st.selectbox("Select category", category_options)

if category != "Select a category...":
    with st.spinner("Analyzing..."):
        rfm_df = build_rfm(simulated_df[simulated_df['category'] == category], 'timestamp', 'order_id', 'user_id', 'total_price')

    rfm_df["is_vip"] = (rfm_df['Segment'] != others_label).astype(int)
    is_vip_df = rfm_df[["is_vip"]]

    # Merge demographics and behavioral (excluding purchase outcomes)
    user_traits = simulated_df.groupby('user_id').agg({
        'category': lambda x: x.value_counts().idxmax(),
        'age': 'first',
        'gender': 'first',
        'country': 'first',
        'traffic_source': 'first',
        'device': 'first',
    }).rename(columns={'category': 'top_category'}).reset_index()
    df_fashion = is_vip_df.merge(user_traits, on='user_id')

    # Prepare features for tree
    X = pd.get_dummies(df_fashion[['age', 'gender', 'country', 'traffic_source', 'device']], drop_first=True)
    y = df_fashion['is_vip']
    # Train decision tree
    clf = DecisionTreeClassifier(max_depth=3, random_state=42)
    clf.fit(X, y)

    # Extract rules
    rules = export_text(clf, feature_names=list(X.columns))

    parsed_lines = rules.split('\n')
    translated = []
    current_path = []

    for line in parsed_lines:
        if not line.strip():
            continue
        depth, sentence = parse_rule_line(line)
        current_path = current_path[:depth]
        current_path.append(sentence)
        if sentence.startswith("THEN"):
            translated.append(" â†’ ".join(current_path))


    leaf_ids = clf.apply(X)
    # print(rfm_df.shape, leaf_ids.shape)

    rfm_df['leaf_id'] = leaf_ids


    leaf_stats = rfm_df.reset_index().groupby('leaf_id').agg({
        'user_id': 'nunique',
        'Monetary': 'sum',
        'is_vip': 'sum'
    }).rename(columns={
        'user_id': 'Number of Users',
        'Monetary': 'Revenue',
        'is_vip': 'Number of VIP Users'
    }).reset_index()

    readable_rules_df = pd.DataFrame({'Readable Rule': translated})

    readable_rules_df['leaf_id'] = leaf_stats['leaf_id'].values

    readable_rules_df = readable_rules_df.merge(leaf_stats, on='leaf_id')

    readable_rules_df['Revenue'] = readable_rules_df['Revenue'].apply(lambda x: f"{x/1000:.0f}k")

    df_display = readable_rules_df.reset_index(drop=True)
    df_display.index = [''] * len(df_display)

    st.write()

    st.write("Below, you can see the generated rules. Each rule defines an audience segment for the selected category. For each rule, we show the cumulative revenue generated by that audience.")
    st.dataframe(df_display[['Readable Rule', 'Revenue', 'Number of Users', 'Number of VIP Users']], use_container_width=True)
    st.markdown("""
    #### How This Works
    
    Algorithm analyzes your customers to understand what makes your top buyers unique.
    
    First, we identify your **VIP customers**â€”those who spend the most in this category. Then, we examine their **demographics and behavior** to discover common patterns.
    
    Our system uses a decision tree to uncover simple, explainable rules like:
    > "VIPs are often women aged 25â€“35 who shop from mobile devices and come from Instagram."
    
    These rules help you create **precise audience segments** you can target in your Ads campaigns to attract more high-value customers.
    """)

st.markdown("""
---

#### What Else We Can Do

We help you turn your raw data into actionable targeting strategies for ads that convert.
Here are just a few ways we can support your campaigns:

 
ðŸ§­ **Lookalike Audience Modeling** â€“ find non-buyers who behave like your VIPs  
ðŸ“¦ **Product-Segment Matching** â€“ identify which products resonate with which personas  
ðŸ“¤ **Exportable Targeting Profiles** â€“ generate ready-to-use audience definitions for Meta Ads campaigns
ðŸ§¬ **Audience Persona Discovery** â€“ uncover who your top buyers really are based on behavior and demographics  
ðŸ“Š **Segment Scoring & Prioritization** â€“ rank customer segments by revenue, conversion, or campaign potential 
  
"""

)

st.markdown(CALL)

submission = show_email_form()

if submission:
    # Optional: log it or send to email / CSV / database
    st.write("Captured email:", submission["email"])